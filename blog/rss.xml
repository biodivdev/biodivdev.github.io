<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Biodiversity Development and Rapid Risk Assessment Application</title>
    <link>http://localhost:8585</link>
    <description>Updates on Biodivdev and RRAPP.</description>
    
    <item>
      <title><![CDATA[Running at Rio de Janeiro Botanical Garden's infrastructure]]></title>
      <link>http://localhost:8585/post/jbrj-infrastructure.html</link>
      <guid>jbrj-infrastructure</guid>
      <pubDate>2017-03-01</pubDate>
      <description><![CDATA[<p>Even if <a href="https://br.biodiversity.cloud">RRAPP</a> was initially developed inside Brazil's <a href="http://cncflora.jbrj.gov.br">National Centre for Flora Conservation</a>, of <a href="http://jbrj.gov.br">Rio de Janeiro Botanical Garden</a>, it was runing at my personal (Diogo) servers at <a href="https://scaleway.com">Scaleway</a>.</p>

<p>Now with the research institute being able to provide new server the project will be able to grow in data size,  that was already limited on a single server.</p>
]]></description>
    </item>
    
    <item>
      <title><![CDATA[Featured at Elastic.co]]></title>
      <link>http://localhost:8585/post/elastic.html</link>
      <guid>elastic</guid>
      <pubDate>2017-02-24</pubDate>
      <description><![CDATA[<p>The <a href="https://br.biodiversity.cloud">Rapid Automated Risk Assessment</a> tool was shortlisted for this yearâ€™s inaugural <a href="https://www.elastic.co/causeawards">Elastic Cause Awards</a>, which recognizes organizations using the Elastic Stack to do great good in the world.</p>

<p>Our recommendation was a great surprise, specially since we were selected without prior submission. Even if we were not selected for the final award, it was still a nice recognition.</p>

<p>All given they invited us to share our story on <a href="https://www.elastic.co/blog/providing-extinction-risk-assessments-for-biodiversity-with-elasticsearch">Providing extinction risk assessments for biodiversity with Elasticsearch</a> on their featured blog.</p>
]]></description>
    </item>
    
    <item>
      <title><![CDATA[New configuration]]></title>
      <link>http://localhost:8585/post/new-configuration.html</link>
      <guid>new-configuration</guid>
      <pubDate>2016-12-30</pubDate>
      <description><![CDATA[<p>One main improvement of latest update is the review of the whole configuration of the RRAPP.</p>

<p>Since there has been some interest on running it by different parties (this is the intention after all), it was clear that the current way to run it was overly complicated.</p>

<p>This post describe a initial approach to simplify this work.</p>

<h2>Published data</h2>

<p>The main requirement to be able to run RRAPP is actually a data availability issue. You MUST have:</p>

<ul>
<li>A taxonomic checklist published on IPT</li>
<li>Occurrences with coordinates published on IPT</li>
</ul>

<h2>Composition of apps</h2>

<p>One thing that is important to consider is that RRAPP is not a single tool, but actually a composition of three parts:</p>

<ul>
<li>The data bot</li>
<li>The data analyzer</li>
<li>The web interface</li>
</ul>

<p>All along with a ElasticSearch database and a Proxy to better serve the content.</p>

<p>As such there is two approaches: Run all as whole (using docker-compose) or running individual parts.</p>

<h3>The ElasticSearch database</h3>

<p>RRAPP uses the latest ElasticSearch 5.0 release. This is the single storage/database used.</p>

<p>A common problem when running newest ES is &quot;max virtual memory areas vm.max_map_count [65530] likely too low&quot;, that is solved by running &quot;sudo sysctl -w vm.max_map_count=262145&quot;. But this change is transient, and will be overriden at reboot. To make it permanent, as root: &quot;echo vm.max_map_count=262145 &gt; /etc/sysctl.d/50-es.conf&quot;.</p>

<h3>The Proxy</h3>

<p>Not mandatory if you are running each app on it's own, but useful anyway, is the proxy. Here the choice is Caddyserver, a new proxy server capable of automaticaly serving HTTPS sites and easy to configure.</p>

<p>In the compose repository, it is configured at config/Caddyfile, which tells to which address the proxy will bind and serve, defaulting to http://localhost:8080.</p>

<p>It can be configured to simply bind to a port (eg.: &quot;:8080&quot;) or to a domain (e.g &quot;https://br.biodiversity.cloud&quot;), if you wish to enable HTTPS you must also provide the directive &quot;tls email@domain.com&quot; in any other line.</p>

<h3>Configuration files</h3>

<h4>dwc-bot.list</h4>

<p>This file consist of a list of IPT URLs for the bot to crawl and index, it is simply a list with a single url in each line that points to a IPT intallation.</p>

<h4>config.ini</h4>

<p>The three main app use this file to run, and the bot and the analyzer(idx) will reload it on rerun.</p>

<p>It configures:</p>

<ul>
<li>ELASTICSEARCH: the address of the elasticsearch server</li>
<li>INDEX: The index (database) to use on elasticsearch. Will be created if needed.</li>
<li>SOURCE: The name of the crawled resource from which to load the taxonomic checklist</li>
<li>LOOP: Used by the bot and idx to run only once or keep running.</li>
</ul>

<p>When running the apps individually, all theses parameters can also be overriden by environment variables of java properties on execution, and so is the location of the file on env var CONFIG.</p>

<h2>Conclusion</h2>

<p>This is a work in progress, but as always if you have problems or suggestions you can interact in Github with the issues pages of each project or direct with email with diogo@diogok.net.</p>
]]></description>
    </item>
    
  </channel>
</rss>
